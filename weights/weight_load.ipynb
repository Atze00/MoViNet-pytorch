{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ambient-trail",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "sys.path.append('..')\n",
    "from movinets import MoViNet\n",
    "from movinets.config import _C\n",
    "import torch\n",
    "from einops import rearrange\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-private",
   "metadata": {},
   "source": [
    "# Example of weight loading\n",
    "## Loading the weights in Tensorflow\n",
    "The link used is the one for the A5 model, and this example will continue loading the weights for that specific model. <br>\n",
    "To load the weights of a different model change now the link of the model. <br>\n",
    "A0 : \"https://tfhub.dev/tensorflow/movinet/a0/base/kinetics-600/classification/2\"<br>\n",
    "A1 : \"https://tfhub.dev/tensorflow/movinet/a1/base/kinetics-600/classification/2\"<br>\n",
    "A2 : \"https://tfhub.dev/tensorflow/movinet/a2/base/kinetics-600/classification/2\"<br>\n",
    "A3 : \"https://tfhub.dev/tensorflow/movinet/a3/base/kinetics-600/classification/2\"<br>\n",
    "A4 : \"https://tfhub.dev/tensorflow/movinet/a4/base/kinetics-600/classification/2\"<br>\n",
    "A5 : \"https://tfhub.dev/tensorflow/movinet/a5/base/kinetics-600/classification/2\"<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "specific-tampa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(\n",
    "    shape=[None, None, None, 3],\n",
    "    dtype=tf.float32)\n",
    "\n",
    "encoder = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/tensorflow/movinet/a0/base/kinetics-600/classification/3\")\n",
    "\n",
    "# Important: due to a bug in the tf.nn.conv3d CPU implementation, we must\n",
    "# compile with tf.function to enforce correct behavior. Otherwise, the output\n",
    "# on CPU may be incorrect.\n",
    "encoder.call = tf.function(encoder.call, experimental_compile=True)\n",
    "\n",
    "# [batch_size, 600]\n",
    "outputs = encoder(dict(image=inputs))\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "#save the weights of the pretrained model in a list\n",
    "loaded_list = []\n",
    "for item in encoder.variables:\n",
    "  loaded_list.append((item.name,item.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-raise",
   "metadata": {},
   "source": [
    "## Loading Weights in the pytorch model\n",
    "Change now the model name with the one that matches the TF model loaded in the previous step.\n",
    "Different models have sligtly different behaviour.\n",
    "```python\n",
    "model_name = \"modelA0\" \n",
    "model_name = \"modelA1\"\n",
    "model_name = \"modelA2\"\n",
    "model_name = \"modelA3\"  \n",
    "model_name = \"modelA4\"   \n",
    "model_name = \"modelA5\" \n",
    "```\n",
    "Change the loaded pytorch model <br>\n",
    "```python\n",
    "model = MoViNet(_C.MODEL.MoViNetA0, 600,causal = False, tf_like = True)\n",
    "model = MoViNet(_C.MODEL.MoViNetA1, 600,causal = False, tf_like = True)\n",
    "model = MoViNet(_C.MODEL.MoViNetA2, 600,causal = False, tf_like = True)\n",
    "model = MoViNet(_C.MODEL.MoViNetA3, 600,causal = False, tf_like = True)\n",
    "model = MoViNet(_C.MODEL.MoViNetA4, 600,causal = False, tf_like = True)\n",
    "model = MoViNet(_C.MODEL.MoViNetA5, 600,causal = False, tf_like = True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "addressed-inspiration",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"modelA0\" \n",
    "\n",
    "def key_translate_base( k):\n",
    "    k = (k\n",
    "    .replace(\"classifier_head/head/conv3d/\" ,\"classifier.0.conv_1.conv3d.\")\n",
    "    .replace(\"classifier_head/classifier/conv3d/\", \"classifier.3.conv_1.conv3d.\")\n",
    "    .replace(\"se/se_reduce/conv3d/\",\"se.fc1.conv_1.conv3d.\")\n",
    "    .replace(\"se/se_expand/conv3d/\",\"se.fc2.conv_1.conv3d.\")\n",
    "    .replace(\"stem/stem/\", \"conv1.conv_1.\")\n",
    "    .replace(\"conv3d/\", \"conv3d.\")\n",
    "    .replace(\"kernel:0\",\"weight\")\n",
    "    .replace(\"bias:0\",\"bias\")\n",
    "    .replace(\"bn/gamma:0\",\"norm.weight\")\n",
    "    .replace(\"bn/beta:0\",\"norm.bias\")\n",
    "    .replace(\"bn/moving_mean:0\",\"norm.running_mean\")\n",
    "    .replace(\"bn/moving_variance:0\",\"norm.running_var\")\n",
    "    .replace(\"skip/skip_project/\",\"res.1.conv_1.\")\n",
    "    .replace(\"expansion/\",\"expand.conv_1.\")\n",
    "    .replace(\"feature/\",\"deep.conv_1.\")\n",
    "    .replace(\"projection/\",\"project.conv_1.\")\n",
    "    .replace(\"scale:0\", \"alpha\")\n",
    "    .replace(\"head/project/\", \"conv7.conv_1.\"))\n",
    "    for i in range(5):\n",
    "        for j in range(20):\n",
    "            k=k.replace(f\"b{i}/l{j}/bneck/\", f\"blocks.b{i}_l{j}.\").replace(f\"b{i}/l{j}/\", f\"blocks.b{i}_l{j}.\")\n",
    "    if (model_name == \"modelA3\" or model_name == \"modelA5\") and \"b3_l0\" in k:\n",
    "        k = k.replace(\"res.1.\",\"res.0.\")\n",
    "    return k\n",
    "\n",
    "def key_translate_stream( k):\n",
    "    k = (k.replace(\"feature/conv2d/depthwise_conv2d/depthwise_kernel:0\",\"deep.conv_1.conv2d.weight\")\n",
    "         .replace(\"feature/conv2d_temporal/depthwise_conv2d_1/depthwise_kernel:0\",\"deep.conv_2.conv2d.weight\")\n",
    "         \n",
    "         .replace(\"feature/bn/\",\"deep.conv_1.norm.\")\n",
    "         .replace(\"feature/bn_temporal/\",\"deep.conv_2.norm.\")\n",
    "         .replace(\"expansion/conv2d/conv2d/\",\"expand.conv_1.conv2d.\")\n",
    "         .replace(\"expansion/bn/\",\"expand.conv_1.norm.\")\n",
    "         .replace(\"projection/conv2d/conv2d_3/\",\"project.conv_1.conv2d.\")\n",
    "         .replace(\"projection/bn/\",\"project.conv_1.norm.\")\n",
    "         .replace(\"se/se_reduce/conv2d/conv2d_1/\",\"se.fc1.conv_1.conv2d.\")\n",
    "         .replace(\"se/se_expand/conv2d/conv2d_2/\",\"se.fc2.conv_1.conv2d.\")\n",
    "         .replace(\"skip/skip_project/conv2d/conv2d_4/\", \"res.1.conv_1.conv2d.\")\n",
    "    .replace(\"skip/skip_project/bn/\" ,\"res.1.conv_1.norm.\")\n",
    "         .replace(\"classifier_head/head/conv2d/conv2d/\" ,\"classifier.0.conv_1.conv2d.\")\n",
    "    \n",
    "         .replace(\"classifier_head/classifier/conv2d/conv2d_1/\" ,\"classifier.3.conv_1.conv2d.\")\n",
    "         .replace(\"head/project/bn/\",\"conv7.conv_1.norm.\")\n",
    "         .replace(\"head/project/conv2d/conv2d/\" ,\"conv7.conv_1.conv2d.\")\n",
    "         .replace(\"stem/stem/bn/\",\"conv1.conv_1.norm.\")\n",
    "         .replace(\"stem/stem/conv2d/conv2d/\" ,\"conv1.conv_1.conv2d.\")\n",
    "    .replace(\"kernel:0\",\"weight\")\n",
    "    .replace(\"bias:0\",\"bias\")\n",
    "    .replace(\"gamma:0\",\"weight\")\n",
    "    .replace(\"beta:0\",\"bias\")\n",
    "    .replace(\"moving_mean:0\",\"running_mean\")\n",
    "    .replace(\"moving_variance:0\",\"running_var\")\n",
    "    .replace(\"scale:0\", \"alpha\")\n",
    "        )\n",
    "    for i in range(5):\n",
    "        for j in range(20):\n",
    "            k=k.replace(f\"b{i}/l{j}/bneck/\", f\"blocks.b{i}_l{j}.\").replace(f\"b{i}/l{j}/\", f\"blocks.b{i}_l{j}.\")\n",
    "    if (model_name == \"modelA3\" or model_name == \"modelA5\") and \"b3_l0\" in k:\n",
    "        k = k.replace(\"res.1.\",\"res.0.\")\n",
    "    return k\n",
    "\n",
    "def weight_translate( w):\n",
    "    if len(w.shape)==5:\n",
    "        w = rearrange(w, \"d h w c_in c_out -> c_out c_in d h w\")\n",
    "    if len(w.shape)==4:\n",
    "        #w = rearrange(w, \"h w c_in c_out -> c_out c_in h w\")\n",
    "        if \"feature\" in name:\n",
    "            w = rearrange(w, \"h w c_out c_in-> c_out c_in h w\")\n",
    "        else:\n",
    "            w = rearrange(w, \"h w c_in c_out -> c_out c_in h w\")\n",
    "    return torch.tensor(w)\n",
    "\n",
    "#creating the dictionary\n",
    "param_dict = {key_translate_base(name ) : weight_translate( item) for i,(name,item) in enumerate(loaded_list)}\n",
    "\n",
    "model = MoViNet(_C.MODEL.MoViNetA0, causal = False, num_classes = 600, tf_like = True)\n",
    "#load the dictionary\n",
    "model.load_state_dict(param_dict)\n",
    "#save the model\n",
    "torch.save(model.state_dict(), \"./modelA0_statedict_v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "sustained-agriculture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(554)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from six.moves import urllib\n",
    "from PIL import Image\n",
    "image_url = 'https://upload.wikimedia.org/wikipedia/commons/8/84/Ski_Famille_-_Family_Ski_Holidays.jpg'\n",
    "image_height = 172\n",
    "image_width = 172\n",
    "from io import BytesIO\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "with urllib.request.urlopen(image_url) as f:\n",
    "  image = Image.open(f).resize((image_height, image_width))\n",
    "video = tf.reshape(np.array(image), [1, 1, image_height, image_width, 3])\n",
    "video = tf.cast(video, tf.float32) / 255.\n",
    "video_2 = rearrange(torch.from_numpy(video.numpy()), \"b t h w c-> b c t h w\")\n",
    "model.eval()\n",
    "model.clean_activation_buffers()\n",
    "result = model(video_2)\n",
    "torch.argmax(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-argentina",
   "metadata": {},
   "source": [
    "Run the model and output the predicted label. Expected output should be skiing (labels 464-467). E.g., 465 = \"skiing crosscountry\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-destiny",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
